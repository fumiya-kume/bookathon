= AI活用の実践テクニック

//lead{
第1〜3章で語られた知見を横断し、ハッカソンでも日常業務でも活用できるAI活用の実践テクニックを3人でまとめます。考え方とアプローチを軸にしつつ、必要に応じて具体的なツール名にも触れます。
//}

== AIに正しく仕事をさせる前提条件

AIは放任すると古い知識や誤った前提で動く。だからこそ、正しい方向に導く「ガードレール」──公式ドキュメントの参照、バージョンの明示、ルールファイルの整備──を事前に敷いておくことが重要だ。ここでは、そのガードレールを具体的なテクニックに落とし込む。

=== 「古い知識」を上書きする

@<b>{Kuu}：@<chapref>{01-ai-native-mindset}でガードレールの考え方を話しましたが、具体的な方法として一番効くのは、最新のAPIリファレンスのURLをプロンプトに含めることです。AIに読ませるだけで回答精度が全然違います。

@<b>{Lemio}：ドキュメントのURLを渡すだけでそんなに変わるんですか？

@<b>{Kuu}：変わります。特にJSやPythonはライブラリのバージョン更新が速いので、公式ドキュメントを起点にしないとAIが古いAPIで書いてきます。しかも動くけれど非推奨のAPIを使っていたり、メソッド名が変わっていたりする。動くだけに気づきにくいのが厄介です。

@<b>{Lemio}：エラーが出れば気づけるけど、動いてしまうと見逃しますよね。

@<b>{Kuu}：だからこそ、URLを渡す、バージョンを明示する、この2つだけでつまずきにくくなります。

//blankline

AIの学習データは数ヶ月前のスナップショットであり、日々更新されるライブラリのAPIとは乖離がある。この問題の厄介さは、Kuuが指摘するとおり「動いてしまう」ことにある。非推奨APIで書かれたコードは正常に動作するが、将来のバージョンアップで突然壊れたり、セキュリティパッチが当たらなかったりする。たとえばPythonの@<code>{requests}ライブラリではセッション管理の推奨パターンが変わり、ReactではクラスコンポーネントからHooksへの移行が完了した。しかしAIは学習データの偏りに引きずられ、古い書き方で生成することがある。

対策の手順を整理すると、まず公式ドキュメントのURLをプロンプトの冒頭に記載する。次に「Python 3.12、React 19を使用」のようにバージョンを明示し、@<code>{package.json}や@<code>{requirements.txt}をプロンプトに含める。この2ステップだけで、バージョン間の整合性が取れたコードが生成される。

さらに生成されたコードの@<code>{import}文を確認する習慣をつける。非推奨のモジュールからインポートしていないか、廃止されたパッケージを参照していないかをチェックする。入力品質の重要性については、本章末のアンチパターンの節で改めて扱う。

=== ルールファイルで行動を制御する

@<b>{Kuu}：プロンプトに毎回同じことを書くのは非効率です。Coding Agentには「Agent Skills」と呼ばれる仕組みがあって、プロジェクト固有のルールや慣習を事前に設定ファイルとして渡せる。これを整備しておくと、AIが毎回正しい前提で動いてくれます。

@<b>{Sae}：設定ファイルというのは、どのくらいの粒度で書くんですか？

@<b>{Kuu}：「このプロジェクトではTypeScriptを使う」「テストはVitestで書く」「コミットメッセージはConventional Commitsに従う」くらいの粒度です。プロジェクトのREADMEに書くような情報を、AIが読める形式で置いておくイメージですね。

//blankline

この仕組みの真価は、チーム開発で発揮される。設定ファイルをリポジトリに含めておけば、チームメンバー全員が同じ前提でAIを動かせる。個人のプロンプトスキルに依存せず、AIの出力品質がチーム全体で均一化される。ハッカソンでは特に有効で、初対面のメンバーとも設定ファイルを共有するだけで開発規約の認識が揃う。

API情報の提供もAgent Skillsの重要な要素だ。プロジェクトで使う外部APIについて、エンドポイント一覧・認証方式・レスポンス型定義を設定ファイルに含めておくと、AIはAPIコールのコードを正確に生成できる。特にハッカソンでは、スポンサー企業が提供するAPIを初めて使うことが多い。APIドキュメントのURLと基本的な使い方をAgent Skillsに書いておくことで、チーム全員がAIを通じて素早くAPIを活用できる。

AIの前提知識を整えたら、次はAIへの指示の質を上げる番だ。設計そのものを言語化する技術を見ていこう。

== 設計を言語化する

=== 入出力を言語化する

@<b>{Lemio}：AIの時代に変わったのは、設計を言語化するスキルの重要性です。入力と出力を明確に言葉にできれば、その間の処理はAIが埋めてくれる。逆に言えば、言語化できない設計はAIにも伝わらない。

@<b>{Kuu}：「何を入れて、何が出てくるか」を定義するのが人間の仕事で、「どうやって変換するか」はAIの仕事になった、ということですよね。

@<b>{Lemio}：そうです。「この画面にユーザーが名前を入力すると、パーソナライズされた挨拶が表示される」──この一文があれば、AIはフォーム、バリデーション、表示ロジックまで一気に書ける。設計を言語化する力が、そのままAIの活用力になります。

//blankline

では、AIへの指示を具体的にどう書けばよいのか。鍵は「入力」と「出力」の明示だ。「入力はCSVファイル、出力は月別売上のグラフ、形式はPNG」──この一文があれば、AIはそのとおりに実装する。コードが書けるかどうかは関係ない。

//image[input-process-output][INPUT→PROCESS→OUTPUTモデル]{
//}

実践的なアプローチとして、機能ごとに「入力→処理→出力」の三行を書く方法がある。たとえば「入力：ユーザーの現在地（GPS座標）、処理：半径1km以内のレストランを検索してレビュースコア順にソート、出力：レストラン名・距離・スコアのリスト」と書く。この三行だけで、AIはAPIコール、ソートロジック、データ構造の設計まで一貫したコードを生成できる。

=== Coding Agentで並列開発する

@<b>{Kuu}：Coding Agentの最大の利点は、非同期で動かせることです。人間が一つのタスクに集中している間に、別のタスクをAIに並列で進めてもらう。これはハッカソンでの時間効率を劇的に上げます。

@<b>{Sae}：海外のハッカソンでも、1人が複数のAIエージェントを同時に走らせているチームを見ました。あれはどうやって管理しているんですか？

@<b>{Kuu}：git worktreeを使います。一つのリポジトリから複数の作業ディレクトリを作って、それぞれに別のCoding Agentを割り当てる。Agent Aにはフロントエンドを、Agent Bにはバックエンドを、自分はインフラの設定をやる、という具合です。

//blankline

//image[parallel-dev][git worktreeによる並列開発]{
//}

git worktreeは、一つのリポジトリから複数の作業ツリーを作成するGitの機能だ。通常のブランチ切り替えと異なり、物理的に別のディレクトリとして存在するため、それぞれのディレクトリで独立してCoding Agentを起動できる。メインのworktreeでは自分がUI設計を進め、別のworktreeではAgent AがAPI実装を進め、さらに別のworktreeではAgent Bがテストコードを書く──人間はディレクションに徹しながら、複数のタスクを同時に前進させられる。

ハッカソンでは時間が限られているからこそ、この手法の効果は大きい。3人チームで6時間のハッカソンに参加する場合、各メンバーが2〜3のCoding Agentを並列で動かせば、実質的な作業量は数倍に膨らむ。ただし、並列化の前提として、タスクの分割と依存関係の整理が不可欠だ。依存関係が複雑なタスクを並列で進めるとコンフリクトが頻発し、かえって時間を浪費する。

=== master直push戦略

@<b>{Kuu}：ハッカソンでは、あえてmasterブランチに直接pushする戦略を取ることがあります。通常の開発ではブランチを切ってプルリクエストを出すのが常識ですが、2〜3日の短期決戦ではそのオーバーヘッドが致命的です。

@<b>{Lemio}：コンフリクトの解消に時間を取られるリスクはないですか？

@<b>{Kuu}：あります。だからこそ、タスクの分割が重要です。フロントエンドとバックエンドで明確にディレクトリを分けたり、ファイルの担当を決めたりして、物理的にコンフリクトが起きにくい構造を先に作る。それでもコンフリクトが起きたときは、AIに「Please fix conflict」と指示すれば、大半の場合は自動で解決してくれます。

@<b>{Kuu}：CDがあることで、開発者がmasterにpushするだけで自動デプロイされ、検証者はブラウザをリロードするだけで最新版を試せます。手動でやると死にますが、CDなら自動です。

@<b>{Sae}：ダメだったらすぐエラーでわかるし、ロールバックもできますしね。

//blankline

ハッカソン限定の戦略として、master直pushは有効だ。CD（Continuous Deployment）と組み合わせることで、さらに効果が増す。

通常の開発プロセスでは、コードレビューとブランチ管理が品質を担保する。しかしハッカソンの時間制約下では、プロセスの厳密さよりアウトプットの速度が優先される。

master直push戦略の前提条件として、チームメンバー全員の担当領域分割、CIパイプラインの設定（pushのたびにビルドとテストが自動実行される状態）、コンフリクト発生時にAIで即座に解決する体制が必要だ。

//note[master直push戦略の3つの前提条件]{
チームメンバー全員の担当領域分割、CIパイプラインの設定（pushのたびにビルドとテストが自動実行される状態）、コンフリクト発生時にAIで即座に解決する体制。この3つが揃わないまま直pushすると混乱を招く。
//}

CIが失敗した場合のプロンプトも定型化しておくとよい。CIのエラーログをCoding Agentに渡して「このエラーを修正してください」と指示する──これだけでCoding Agentはエラーを解析し、修正コミットを生成する。

さらに効果を発揮するのがCDの併用だ。masterへのpushをトリガーにステージング環境へ自動デプロイする仕組みを用意しておくと、開発者以外のチームメンバーはブラウザをリロードするだけで最新の状態を確認できる。「開発者1人＋検証者複数人」という体制が自然に成立し、コードを書かないメンバーも即座にフィードバックを返せる。

CIが失敗したらデプロイを止めてロールバックすれば、常に動く状態が保たれる。CDは自動テストの役割も兼ねており、デプロイが通ること自体が「少なくともビルドと基本動作は壊れていない」という確認になる。

この戦略はあくまでハッカソンや短期プロトタイピングに限定した手法であり、長期運用のプロダクトには従来のブランチ運用を推奨する。

== AIを学習パートナーにする

=== 何度でも聞き直せるAI家庭教師

@<b>{Lemio}：わかるまで聞けばいいんです。「わからない部分をもう一度説明してください」と何度でも聞く。そのやり方をレクチャーするのが、ググり方を教えるのと同じ感覚ですね。

@<b>{Kuu}：やり方さえわかれば、自走できますしね。

//blankline

Lemioが言う「わかるまで聞く」を実践するには、聞き方にコツがある。「わかりません」とだけ伝えるのではなく、「ここまでは理解できたが、ここから先がわからない」と境界を示す。AIは理解の境界線を起点に、より噛み砕いた説明を返してくれる。

たとえば「Dockerの仕組みがわかりません」よりも、「コンテナが仮想マシンと違うことは理解したが、イメージとコンテナの関係がわからない」と伝えた方が、的確な回答が得られる。この「わかる境界」を伝えるスキルは、AI活用だけでなく、人間同士のコミュニケーションでも応用が利く。

この手法をチームに広めることは、かつて「ググり方を教える」のと同じだ。検索エンジンの登場時、「何をどう検索するか」を知っている人と知らない人で情報アクセスの格差が生まれた。AIの時代も同様で、「AIにどう聞くか」を知っている人と知らない人で学習速度の格差が生まれる。聞き方のスキルを共有すること自体が、チームの底上げになる。

=== 未知の概念を段階的に深掘りする

@<b>{Lemio}：昔テレビで見たんですが、アイヌの方にアイヌ語を教えてもらうとき、ぐちゃぐちゃの絵を描いて見せて、相手の反応から語彙を学んでいく方法がありました。わからないことさえわかっていれば、知識を広げられます。AIも同じように使えばいいんです。

@<b>{Kuu}：自分がわからないことさえわかっていれば、わかっている部分とわからない部分の境界を伝えて、わからない部分だけを深掘りしていけば全体が見えてきます。

//blankline

未知の概念に向き合うとき、最初の壁は「何がわからないかがわからない」状態だ。この壁を越える方法として、AIに断片的な情報を投げて反応を見るアプローチがある。

たとえば、新しいフレームワークの概念を学びたいとき、自分が知っている類似概念をAIに伝える。「Reactのstateに似たものがSvelteにもあると思うが、何と呼ぶのか」と聞けば、AIは「Svelteではリアクティブ変数と呼び、$: という構文で宣言する」と教えてくれる。既知の概念を足がかりに、未知の領域を探索する手法だ。

既知→未知の段階的深掘りは、ハッカソンで特に価値がある。限られた時間の中で、初めて触る技術スタックを学ばなければならない場面は多い。「何がわからないかを整理して、AIに段階的に聞く」というアプローチを身につけておけば、新技術のキャッチアップ速度が格段に上がる。

== 音声AIの活用

=== 曖昧な表現で検索する

@<b>{Kuu}：テキスト検索だと言葉に言語化しなければなりませんが、音声なら擬音語やオノマトペを使って、ふわっとした形から絞り込んでいくことができます。

@<b>{Lemio}：昔見たYouTubeの動画で、タイトルが全然わからなくても、「こういう感じのやつ」と探していったら出てきたりするんですよ。

//blankline

テキスト検索には構造的な限界がある。検索したいものの正確な名前や用語を知らなければ、検索クエリを組み立てられない。しかし音声AIを使えば、言語化が不完全な状態でも検索が成立する。

たとえば、UIのアニメーションパターンを探しているとき、「要素がふわっと現れて、スッと消える感じのやつ」と音声で伝えれば、AIは「フェードイン・フェードアウトのアニメーション」を提案してくれる。テキストで「CSS アニメーション フェード」と検索するには、まず「フェード」という用語を知っている必要がある。音声なら、オノマトペで伝えるだけでよい。

この手法は、デザインの領域で特に効果を発揮する。「なんかこう、カードがペラッとめくれる感じのトランジション」「ボタンを押したときにポヨンと跳ねるアニメーション」──テキスト検索ではたどり着けない表現でも、音声AIは意図を汲み取って適切な技術用語やライブラリに変換してくれる。

ハッカソンでは、デザイナーとエンジニアの間のコミュニケーションにも音声AIの曖昧検索が使える。デザイナーが「ここ、もうちょっとシュッとした感じにしたい」と言ったとき、その曖昧な要望をAIが「余白を増やしてフォントウェイトを細くする」という具体的な実装に変換する。曖昧さを許容する検索は、チーム内の意思疎通の潤滑油にもなる。

従来の検索は「正確なキーワードを知っている人」が有利だった。CSSの@<code>{border-radius}を知らなければ「角丸」にたどり着けなかった。

しかしAIの登場で、「なんかこう、角がまるっとしてて、ちょっと浮いてる感じのカード」と言えば、@<code>{border-radius}と@<code>{box-shadow}の両方を含むコードが返ってくる。正確な技術用語を知らなくても、感覚的な表現でAIが意図を読み取る時代がすでに来ている。

=== 音声インターフェースでプロダクトを差別化する

@<b>{Sae}：ハッカソンでWebサイトやモバイルアプリを作るチームは多いですが、入出力の手段を少し変えるだけで目新しさが生まれます。たとえば入力をテキストではなく音声にするだけで、体験がガラッと変わる。

@<b>{Kuu}：ElevenLabsのボイスエージェントがまさにそうで、ユーザーが声で話した内容をトリガーにして次のアクションを実行できる。「話す」と「操作する」が一体になった、次世代のアプリケーションが作れます。

//blankline

音声インターフェースは、ハッカソンにおけるプロダクトの差別化要素として見過ごされがちだ。多くのチームがWebアプリやモバイルアプリのUI設計に時間を費やす中、入出力の定義を見直すだけで独自性が生まれる。

音声インターフェースの強みは、操作負荷の低さとデモ映えの両立にある。キーボードもタッチも不要なハンズフリー体験は、審査員に「触ったことのない操作感」を与え、記憶に残りやすい。

音声AI技術は急速に進化しており、リアルタイム音声認識と音声合成を組み合わせたボイスエージェントの構築が個人開発者にも手の届く範囲になった。入力を「音声」、出力を「音声＋アクション」と定義するだけで、従来とは異なるプロダクト体験が見えてくる。

== AI活用のアンチパターン

ここまで効果的なAI活用法を紹介してきた。最後に、よく見られる失敗パターンを整理する。

//table[antipatterns][AI活用の5つのアンチパターン]{
アンチパターン	よくある行動	正しいアプローチ
--------------
情報不足で「使えない」と判断	AIの出力が期待と違うと諦める	何の情報が不足していたかを分析する
自分の方が賢いと思い込む	一行ずつコードを指定する	ゴールを示しAIに道筋を考えさせる
ダメだったツールを二度と試さない	3ヶ月前の評価を固定する	定期的にツールを再評価する
無料枠だけで評価する	無料枠の制限で実力を判断する	1ヶ月だけ有料プランを試す
触らずに評論する	使わずに意見だけ述べる	少なくとも数時間は自分で触る
//}

=== 情報不足で「使えない」と判断する

@<b>{Kuu}：AIに十分な情報を与えずに「使えない」と判断してしまう人が多いんです。AIが間違えたのではなく、自分が与えた情報が足りなかったか、間違っていたと捉えるべきです。

@<b>{Lemio}：コンパイルエラーを「叱られてる」と思う感覚に似ていますね。エラーは敵ではなく、何が足りないかを教えてくれている。AIの出力も同じで、期待と違ったら「何を伝え忘れたか」を考える方が建設的です。

//blankline

AIの出力が期待どおりでないとき、「AIが間違えた」と結論づけるのは典型的なアンチパターンだ。Lemioが言うように、これはコンパイルエラーを「叱られている」と感じる心理に似ている。エラーは敵ではなく、何が足りないかを教えてくれるシグナルだ。プロジェクトの前提条件、使用するライブラリのバージョン、期待する出力形式──これらの情報が欠けていれば、AIは推測で補うしかない。

失敗を「失敗」と思って終わるのではなく、「何が足りなかったかを知るための試み」と捉える。うまくいかなかった経験こそが、次のプロンプト設計を磨く材料になる。

=== 自分の方が賢いと思い込む

@<b>{Kuu}：AIを赤ちゃんに教えるような感覚で使う人がいます。全部自分で指示しようとする。でもAIは頼れるパートナーです。まず「どうやるのがベストか調べて」と聞いてから、一緒に進める方がずっとうまくいく。

//blankline

AIに対して過度に細かい指示を出し続けるのもアンチパターンだ。一行ずつコードを指定するような使い方は、自分で書くのと変わらない。AIの強みは、ゴールを示せばそこまでの道筋を自律的に考えられることにある。

効果的なアプローチは、実装に入る前にAIにベストプラクティスをリサーチさせる段階を挟むことだ。「この機能を実装する前に、一般的なアプローチを3つ提案して、それぞれのメリット・デメリットを比較してください」と聞く。AIをリサーチャーとして活用してから実装に進むことで、手戻りが減る。

=== 一度ダメなら二度と試さない

@<b>{Lemio}：3ヶ月前に試して使えなかったツールが、今は全然違うものになっていることがあります。Marpというプレゼンツールも、最初は微妙だったけれど、AIと組み合わせたら最高のワークフローになりました。

@<b>{Lemio}：AI系のツールは進化が速すぎて、3ヶ月前の評価がまったく通用しない。「あれは使えなかった」という記憶を定期的にリセットした方がいいですね。

@<b>{Lemio}：定期的に触り直す「健康診断」みたいな習慣が大事ですね。

@<b>{Sae}：年間契約せずに月額で、その時一番いいものを選び続ける。健康診断、いい言葉ですね。

//blankline

実践的な方法として、四半期に一度、過去に「使えない」と判断したツールを再度試す時間を設けるとよい。自分の「使えないリスト」を定期的に再評価し、印象をリセットする習慣が、ツール選定の精度を上げる。

=== 無料枠だけで評価する

@<b>{Kuu}：無料枠で判断する人が多いですが、有料プランでないと見えない世界がある。ハッカソンに出るなら、1ヶ月だけでも有料プランを試してみてほしいです。

//blankline

無料枠と有料プランでは、応答速度、コンテキスト長、利用可能なモデルが大きく異なる。無料枠の制限された体験で「AIは大したことない」と結論づけるのは、試乗車の速度制限でスポーツカーの性能を判断するようなものだ。際限なく課金する必要はないが、1ヶ月だけ有料プランを試せば、AIの本来の能力を正しく評価できる。

=== 触らずに評論する

@<b>{Kuu}：「AIはまだ使えない」「あのツールは微妙」と言う人に限って、自分では触っていないんですよね。手を動かさないと何もわからない。

//blankline

AIツールについて意見を述べるなら、まず自分で触ることが前提だ。「評論より実装」の原則は、AIツールの評価にもそのまま当てはまる。少なくとも数時間は自分の手で試してから判断する習慣を持ちたい。

== まず一つ試してみる

本章で紹介したテクニックは、ハッカソンだけでなく日常の開発でも活きる。公式ドキュメントのURLをプロンプトに添える、入力と出力を三行で書き出す、AIに「ベストプラクティスを3つ提案して」と聞いてから実装に入る──どれも今日から始められることだ。すべてを一度に取り入れる必要はない。まず一つ試して、手応えを感じたら次のテクニックへ進む。その繰り返しが、AIを「たまに使うツール」から「頼れるパートナー」に変えていく。
